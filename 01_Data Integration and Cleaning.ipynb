{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 - Data Integration & Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Census Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import urllib\n",
    "import numpy as np\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function\n",
    "---------------\n",
    "split_MSA\n",
    "\n",
    "This method takes in a dataframe with MSA and splits into a city_key (largest city)\n",
    "and state_key. This will help facilitate MSA merging\n",
    "\n",
    "Returns dataframe with these two additional features\n",
    "\"\"\"\n",
    "def split_MSA(df):\n",
    "    df['MSA'] = df['MSA'].str.replace('Metro Area', '')\n",
    "    # Need to manually fix how this MSA is written\n",
    "    df.loc[df['MSA'].str.contains(\"Texarkana\"), \"MSA\"] = \"Texarkana, AR-TX\"\n",
    "\n",
    "    #Grab Everything before comma\n",
    "    df['city_key'] = df['MSA'].str.split(\",\").str[0]\n",
    "    # Then grab everything before first hyphen if it has it\n",
    "    df['city_key'] = df['city_key'].str.split(\"-\").str[0].str.strip()\n",
    "    # State will be everying after comma \n",
    "    df['state_key']=df['MSA'].str.split(\",\").str[1].str.strip()\n",
    "    return(df)\n",
    "\n",
    "\"\"\"\n",
    "Function\n",
    "--------\n",
    "append_df\n",
    "\n",
    "This function appends two dataframes\n",
    "\n",
    "Parameters:\n",
    "    input - dataframe to be appended\n",
    "    output - dataframe to be appended onto\n",
    "    \n",
    "Returns a single dataframe \n",
    "\"\"\"\n",
    "def append_df(input,output):\n",
    "    if output.empty:\n",
    "        output=input.copy()\n",
    "    else:\n",
    "        output=pd.concat([output,input])\n",
    "        output.reset_index(drop='Index',inplace=True)\n",
    "    return(output)\n",
    "\n",
    "'''\n",
    "Function\n",
    "-----------\n",
    "var_thresh\n",
    "\n",
    "This function takes in a dataframe and keeps only those varaibles that have a pct\n",
    "non-missing that is above that threshold\n",
    "'''\n",
    "def var_thresh(df, thresh=0.65):\n",
    "    return(df.loc[:, pd.notnull(df).sum() > len (df) *thresh])\n",
    "\n",
    "'''\n",
    "Function\n",
    "---------\n",
    "slim_df\n",
    "\n",
    "This function takes in a list of variables to keep\n",
    "on the the given df. It keep the variables + geography\n",
    "then renames to MSA and drops the first row of variable descriptions\n",
    "'''\n",
    "def slim_df(df, var_list):\n",
    "    var_list.append('GEO.display-label')\n",
    "    df = df.loc[:, var_list]\n",
    "    # Get rid of Micro Areas\n",
    "    df = df.loc[~df['GEO.display-label'].str.contains(\"Micro Area\"), :]\n",
    "    \n",
    "    df = df.rename(index=str, columns={'GEO.display-label': 'MSA'})\n",
    "    df['MSA'] = df[\"MSA\"].astype(str)\n",
    "    # Drop first row of var descriptions\n",
    "    df = df.loc[df.MSA != \"Geography\", :]\n",
    "    # Split MSA into city-state key\n",
    "    return(split_MSA(df))\n",
    "\n",
    "'''\n",
    "Function\n",
    "---------\n",
    "match_crime\n",
    "\n",
    "This function will take in a dataframe and make changes to MSA\n",
    "in order to match crime data\n",
    "'''\n",
    "def match_crime(df):\n",
    "    df.loc[df['MSA'].str.contains('Crestview'),'city_key']='Crestview'\n",
    "    df.loc[df['MSA'].str.contains('Sarasota'),'city_key']='North Port'\n",
    "    df.loc[df['MSA'].str.contains('Louisville'),'city_key']='Louisville'\n",
    "    df.loc[df['MSA'].str.contains('Santa Maria'),'city_key']='Santa Maria'\n",
    "    df.loc[df['MSA'].str.contains('Weirton'),'city_key']='Weirton'\n",
    "    df.loc[df['MSA'].str.contains('San Germán'),'city_key']='San German'\n",
    "    df.loc[df['MSA'].str.contains('Mayagüez'),'city_key']='Mayaguez'\n",
    "    df.loc[df['MSA'].str.contains('Honolulu'),'city_key']='Urban Honolulu'\n",
    "\n",
    "    #State\n",
    "    df.loc[df['MSA'].str.contains('Worcester'),'state_key']='MA-CT'\n",
    "    df.loc[df['MSA'].str.contains('Myrtle Beach'),'state_key']='SC-NC'\n",
    "    df.loc[df['MSA'].str.contains('Salisbury'),'state_key']='MD-DE'\n",
    "    df.loc[df['MSA'].str.contains('Weirton'),'state_key']='WV-OH'\n",
    "    return(df)\n",
    "\n",
    "'''\n",
    "Function\n",
    "--------\n",
    "get_file_name\n",
    "\n",
    "Get the appropriate file name giving year and table code\n",
    "\n",
    "'''\n",
    "def get_file_name(year, table_code):\n",
    "    if year == 2006:\n",
    "        mid = 'EST'\n",
    "    else:\n",
    "        mid = '1YR'\n",
    "    return('ACS_'+str(year)[2:]+\"_%s_\" %mid + table_code)\n",
    "\n",
    "'''\n",
    "Function\n",
    "--------\n",
    "convert_to_int\n",
    "\n",
    "This function takes in a dataframe and list of vars to convert to int\n",
    "'''\n",
    "def convert_to_int(df, int_vars):\n",
    "    df[int_vars] = df[int_vars].astype(int)\n",
    "    return(df)\n",
    "'''\n",
    "Function\n",
    "----------\n",
    "create_proportions\n",
    "\n",
    "This function will take in a list of variables and a single total variable\n",
    "It then creates proportions by dividing each of the variables in the list by the total\n",
    "to create a proportion\n",
    "'''\n",
    "def create_proportions(df,num_list, total_var):\n",
    "    df.loc[:, num_list] = df[num_list].apply(lambda x: x / df[total_var])\n",
    "    del df[total_var]\n",
    "    return(df)\n",
    "\n",
    "\"\"\"\n",
    "function\n",
    "-----------\n",
    "fbi_url_generator\n",
    "\n",
    "This function pulls violent crime spreadsheets from FBI UCR website\n",
    "for a given year\n",
    "\n",
    "It takes in the year of interest and outputs a url string\n",
    "\"\"\"\n",
    "def fbi_url_generator(year):\n",
    "    if 2006 <= year <= 2009:\n",
    "        return('https://www2.fbi.gov/ucr/cius%i/data/documents/'%year +str(year)[2:]+'tbl06.xls')\n",
    "    else:\n",
    "        if 2010 <= year <= 2011:\n",
    "            end = '/tables/table-6/output.xls'\n",
    "        elif 2012 <= year <= 2013:\n",
    "            end = '/tables/6tabledatadecpdf/table-6/output.xls'\n",
    "        elif 2014 <= year <= 2015:\n",
    "            if year == 2014:\n",
    "                mid = 'Table_6_Crime_in_the_United_States_by_Metropolitan_Statistical_Area_2014/output.xls'\n",
    "            else:\n",
    "                mid = 'table_6_crime_in_the_united_states_by_metropolitan_statistical_area_%i.xls/output.xls' %year\n",
    "            end = '/tables/table-6/%s' %mid\n",
    "        elif year == 2016:\n",
    "            end ='/tables/table-4/table-4/output.xls' \n",
    "        hostname = 'https://ucr.fbi.gov/crime-in-the-u.s/%i/crime-in-the-u.s.-%i' %(year, year)\n",
    "        return(hostname + end)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city_key</th>\n",
       "      <th>state_key</th>\n",
       "      <th>unemp_16_ovr</th>\n",
       "      <th>unemp_16_19</th>\n",
       "      <th>unemp_female</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abilene</td>\n",
       "      <td>TX</td>\n",
       "      <td>6.6</td>\n",
       "      <td>23.1</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>Abilene</td>\n",
       "      <td>TX</td>\n",
       "      <td>6.6</td>\n",
       "      <td>23.1</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>734</th>\n",
       "      <td>Abilene</td>\n",
       "      <td>TX</td>\n",
       "      <td>6.6</td>\n",
       "      <td>23.1</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1101</th>\n",
       "      <td>Abilene</td>\n",
       "      <td>TX</td>\n",
       "      <td>6.6</td>\n",
       "      <td>23.1</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1468</th>\n",
       "      <td>Abilene</td>\n",
       "      <td>TX</td>\n",
       "      <td>6.6</td>\n",
       "      <td>23.1</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     city_key state_key unemp_16_ovr unemp_16_19 unemp_female  year\n",
       "0     Abilene        TX          6.6        23.1          5.2  2006\n",
       "367   Abilene        TX          6.6        23.1          5.2  2007\n",
       "734   Abilene        TX          6.6        23.1          5.2  2008\n",
       "1101  Abilene        TX          6.6        23.1          5.2  2009\n",
       "1468  Abilene        TX          6.6        23.1          5.2  2010"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#####################\n",
    "# Employment Data\n",
    "#####################\n",
    "emp_all = pd.DataFrame()\n",
    "for year in range(2006, 2017):\n",
    "    f = get_file_name(2006, 'S2301')\n",
    "    employ = pd.read_csv(\"data/employ/%s.csv\" %f, encoding='Latin-1')\n",
    "    \n",
    "    # Grab Unemployment\n",
    "    un = [v for v in employ.columns if \"HC04\" in v and \"EST\" in v]\n",
    "    employ = slim_df(employ, un)\n",
    "    \n",
    "    employ = employ.loc[:, [\"MSA\", \"city_key\", \"state_key\", \n",
    "                          \"HC04_EST_VC01\", \"HC04_EST_VC03\",\n",
    "                         'HC04_EST_VC24']]\n",
    "    employ['year'] = year\n",
    "    emp_all = append_df(employ, emp_all) \n",
    "\n",
    "# Process Final DataFrame\n",
    "emp_all = emp_all.sort_values(['city_key', 'state_key', 'year'])\n",
    "emp_all = match_crime(emp_all)\n",
    "del emp_all['MSA']\n",
    "emp_all = emp_all.rename(index=str,\n",
    "                        columns={'HC04_EST_VC01': 'unemp_16_ovr',\n",
    "                                'HC04_EST_VC03': 'unemp_16_19',\n",
    "                                'HC04_EST_VC24': 'unemp_female'})\n",
    "emp_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city_key</th>\n",
       "      <th>state_key</th>\n",
       "      <th>median_age</th>\n",
       "      <th>sex_ratio</th>\n",
       "      <th>male_pop</th>\n",
       "      <th>female_pop</th>\n",
       "      <th>pop_15_19</th>\n",
       "      <th>pop_20_24</th>\n",
       "      <th>male_pop_20_24</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abilene</td>\n",
       "      <td>TX</td>\n",
       "      <td>34.4</td>\n",
       "      <td>99.1</td>\n",
       "      <td>0.497717</td>\n",
       "      <td>0.502283</td>\n",
       "      <td>8.3</td>\n",
       "      <td>8.7</td>\n",
       "      <td>10.2</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>Abilene</td>\n",
       "      <td>TX</td>\n",
       "      <td>34.9</td>\n",
       "      <td>99.1</td>\n",
       "      <td>0.497777</td>\n",
       "      <td>0.502223</td>\n",
       "      <td>9.5</td>\n",
       "      <td>7.7</td>\n",
       "      <td>8.6</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>736</th>\n",
       "      <td>Abilene</td>\n",
       "      <td>TX</td>\n",
       "      <td>34.6</td>\n",
       "      <td>101.0</td>\n",
       "      <td>0.502381</td>\n",
       "      <td>0.497619</td>\n",
       "      <td>9.2</td>\n",
       "      <td>7.6</td>\n",
       "      <td>8.9</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1105</th>\n",
       "      <td>Abilene</td>\n",
       "      <td>TX</td>\n",
       "      <td>33.2</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.492269</td>\n",
       "      <td>0.507731</td>\n",
       "      <td>7.9</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.6</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1479</th>\n",
       "      <td>Abilene</td>\n",
       "      <td>TX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.501355</td>\n",
       "      <td>0.498645</td>\n",
       "      <td>7.3</td>\n",
       "      <td>9.5</td>\n",
       "      <td>9.9</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     city_key state_key median_age sex_ratio  male_pop  female_pop pop_15_19  \\\n",
       "0     Abilene        TX       34.4      99.1  0.497717    0.502283       8.3   \n",
       "367   Abilene        TX       34.9      99.1  0.497777    0.502223       9.5   \n",
       "736   Abilene        TX       34.6     101.0  0.502381    0.497619       9.2   \n",
       "1105  Abilene        TX       33.2      97.0  0.492269    0.507731       7.9   \n",
       "1479  Abilene        TX        NaN       NaN  0.501355    0.498645       7.3   \n",
       "\n",
       "     pop_20_24 male_pop_20_24  year  \n",
       "0          8.7           10.2  2006  \n",
       "367        7.7            8.6  2007  \n",
       "736        7.6            8.9  2008  \n",
       "1105       9.0            9.6  2009  \n",
       "1479       9.5            9.9  2010  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############\n",
    "# Age Data\n",
    "############\n",
    "age_all = pd.DataFrame()\n",
    "for year in range(2006, 2017):\n",
    "    f = get_file_name(year, 'S0101')\n",
    "    age = pd.read_csv(\"data/age/%s.csv\" %f, encoding='Latin-1')\n",
    "    age = slim_df(age, [v for v in age.columns if \"EST\" in v])\n",
    "    age = age.replace(\"(X)\", np.nan)\n",
    "\n",
    "    age = age.loc[:, ['MSA','city_key','state_key',\n",
    "                      'HC01_EST_VC33','HC01_EST_VC34',\n",
    "                      'HC01_EST_VC01', 'HC02_EST_VC01',\n",
    "                      'HC03_EST_VC01', 'HC01_EST_VC06',\n",
    "                      'HC01_EST_VC07', 'HC02_EST_VC07']]\n",
    "    age['year'] = year\n",
    "    age_all = append_df(age, age_all) \n",
    "\n",
    "\n",
    "# Process Final DataFrame\n",
    "age_all = age_all.sort_values(['city_key', 'state_key', 'year'])\n",
    "age_all = age_all.rename(index=str,\n",
    "                         columns={'HC01_EST_VC33':'median_age',\n",
    "                                'HC01_EST_VC34': 'sex_ratio',\n",
    "                                'HC01_EST_VC01': 'total_pop',\n",
    "                                'HC02_EST_VC01': 'male_pop',\n",
    "                                'HC03_EST_VC01': 'female_pop',\n",
    "                                'HC01_EST_VC06': 'pop_15_19',\n",
    "                                'HC01_EST_VC07': 'pop_20_24',\n",
    "                                'HC02_EST_VC07': 'male_pop_20_24'})\n",
    "\n",
    "# Convert to Int and Get Proportions\n",
    "age_all = convert_to_int(age_all, ['total_pop', 'male_pop', 'female_pop'])\n",
    "age_all = create_proportions(age_all, ['male_pop', 'female_pop'], 'total_pop')\n",
    "# Match Crime Data and then get rid of MSA\n",
    "age_all = match_crime(age_all)\n",
    "del age_all['MSA']\n",
    "age_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inc_lt10</th>\n",
       "      <th>inc_10_15</th>\n",
       "      <th>inc_15_19</th>\n",
       "      <th>inc_20_24</th>\n",
       "      <th>inc_25_29</th>\n",
       "      <th>inc_30_34</th>\n",
       "      <th>inc_35_39</th>\n",
       "      <th>inc_40_44</th>\n",
       "      <th>inc_45_49</th>\n",
       "      <th>inc_50_59</th>\n",
       "      <th>inc_60_74</th>\n",
       "      <th>inc_75_99</th>\n",
       "      <th>inc_100_124</th>\n",
       "      <th>inc_125_149</th>\n",
       "      <th>inc_150_199</th>\n",
       "      <th>inc_gt_200</th>\n",
       "      <th>city_key</th>\n",
       "      <th>state_key</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.066006</td>\n",
       "      <td>0.039355</td>\n",
       "      <td>0.191044</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.034552</td>\n",
       "      <td>0.051751</td>\n",
       "      <td>0.094980</td>\n",
       "      <td>0.044159</td>\n",
       "      <td>0.004803</td>\n",
       "      <td>0.138829</td>\n",
       "      <td>0.060738</td>\n",
       "      <td>0.099628</td>\n",
       "      <td>0.004029</td>\n",
       "      <td>0.006508</td>\n",
       "      <td>0.018748</td>\n",
       "      <td>0.002014</td>\n",
       "      <td>Abilene</td>\n",
       "      <td>TX</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.042883</td>\n",
       "      <td>0.102766</td>\n",
       "      <td>0.078153</td>\n",
       "      <td>0.191829</td>\n",
       "      <td>0.056077</td>\n",
       "      <td>0.063436</td>\n",
       "      <td>0.136514</td>\n",
       "      <td>0.011165</td>\n",
       "      <td>0.071048</td>\n",
       "      <td>0.108094</td>\n",
       "      <td>0.062928</td>\n",
       "      <td>0.046435</td>\n",
       "      <td>0.025121</td>\n",
       "      <td>0.003552</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Albany</td>\n",
       "      <td>NY</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.111215</td>\n",
       "      <td>0.064565</td>\n",
       "      <td>0.078066</td>\n",
       "      <td>0.069276</td>\n",
       "      <td>0.056352</td>\n",
       "      <td>0.080003</td>\n",
       "      <td>0.071902</td>\n",
       "      <td>0.061101</td>\n",
       "      <td>0.054006</td>\n",
       "      <td>0.094082</td>\n",
       "      <td>0.101140</td>\n",
       "      <td>0.101661</td>\n",
       "      <td>0.034098</td>\n",
       "      <td>0.007486</td>\n",
       "      <td>0.009591</td>\n",
       "      <td>0.005456</td>\n",
       "      <td>Albuquerque</td>\n",
       "      <td>NM</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.150833</td>\n",
       "      <td>0.063611</td>\n",
       "      <td>0.084792</td>\n",
       "      <td>0.084514</td>\n",
       "      <td>0.105903</td>\n",
       "      <td>0.057778</td>\n",
       "      <td>0.043542</td>\n",
       "      <td>0.024583</td>\n",
       "      <td>0.080417</td>\n",
       "      <td>0.095417</td>\n",
       "      <td>0.075556</td>\n",
       "      <td>0.068958</td>\n",
       "      <td>0.042639</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021458</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Allentown</td>\n",
       "      <td>PA-NJ</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.084392</td>\n",
       "      <td>0.086299</td>\n",
       "      <td>0.077275</td>\n",
       "      <td>0.135104</td>\n",
       "      <td>0.043213</td>\n",
       "      <td>0.134596</td>\n",
       "      <td>0.061642</td>\n",
       "      <td>0.051856</td>\n",
       "      <td>0.037239</td>\n",
       "      <td>0.120742</td>\n",
       "      <td>0.054270</td>\n",
       "      <td>0.070285</td>\n",
       "      <td>0.011185</td>\n",
       "      <td>0.022496</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009405</td>\n",
       "      <td>Amarillo</td>\n",
       "      <td>TX</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   inc_lt10  inc_10_15  inc_15_19  inc_20_24  inc_25_29  inc_30_34  inc_35_39  \\\n",
       "0  0.066006   0.039355   0.191044   0.142857   0.034552   0.051751   0.094980   \n",
       "1  0.042883   0.102766   0.078153   0.191829   0.056077   0.063436   0.136514   \n",
       "2  0.111215   0.064565   0.078066   0.069276   0.056352   0.080003   0.071902   \n",
       "3  0.150833   0.063611   0.084792   0.084514   0.105903   0.057778   0.043542   \n",
       "4  0.084392   0.086299   0.077275   0.135104   0.043213   0.134596   0.061642   \n",
       "\n",
       "   inc_40_44  inc_45_49  inc_50_59  inc_60_74  inc_75_99  inc_100_124  \\\n",
       "0   0.044159   0.004803   0.138829   0.060738   0.099628     0.004029   \n",
       "1   0.011165   0.071048   0.108094   0.062928   0.046435     0.025121   \n",
       "2   0.061101   0.054006   0.094082   0.101140   0.101661     0.034098   \n",
       "3   0.024583   0.080417   0.095417   0.075556   0.068958     0.042639   \n",
       "4   0.051856   0.037239   0.120742   0.054270   0.070285     0.011185   \n",
       "\n",
       "   inc_125_149  inc_150_199  inc_gt_200     city_key state_key  year  \n",
       "0     0.006508     0.018748    0.002014      Abilene        TX  2006  \n",
       "1     0.003552     0.000000    0.000000       Albany        NY  2006  \n",
       "2     0.007486     0.009591    0.005456  Albuquerque        NM  2006  \n",
       "3     0.000000     0.021458    0.000000    Allentown     PA-NJ  2006  \n",
       "4     0.022496     0.000000    0.009405     Amarillo        TX  2006  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###############\n",
    "# Income Data\n",
    "###############\n",
    "inc_all = pd.DataFrame()\n",
    "for year in range(2006, 2017):\n",
    "    f = get_file_name(year, 'B19001F')\n",
    "    inc = pd.read_csv(\"data/house_income/%s.csv\" %f, encoding='Latin-1')\n",
    "    # Keep only the estimates\n",
    "    inc = slim_df(inc, [v for v in inc.columns if \"HD01\" in v])\n",
    "    inc['year'] = year\n",
    "    inc_all = append_df(inc, inc_all) \n",
    "\n",
    "# Proccess Final Data Frame\n",
    "inc_all =  inc_all.rename(index=str,\n",
    "                          columns={'HD01_VD01':'total',\n",
    "                                  'HD01_VD02': 'inc_lt10',\n",
    "                                  'HD01_VD03': 'inc_10_15',\n",
    "                                  'HD01_VD04': 'inc_15_19',\n",
    "                                  'HD01_VD05': 'inc_20_24',\n",
    "                                  'HD01_VD06': 'inc_25_29',\n",
    "                                  'HD01_VD07': 'inc_30_34',\n",
    "                                  'HD01_VD08': 'inc_35_39',\n",
    "                                  'HD01_VD09': 'inc_40_44',\n",
    "                                  'HD01_VD10': 'inc_45_49',\n",
    "                                  'HD01_VD11': 'inc_50_59',\n",
    "                                  'HD01_VD12': 'inc_60_74',\n",
    "                                  'HD01_VD13':'inc_75_99',\n",
    "                                  'HD01_VD14':'inc_100_124',\n",
    "                                  'HD01_VD15':'inc_125_149',\n",
    "                                  'HD01_VD16':'inc_150_199',\n",
    "                                  'HD01_VD17':'inc_gt_200'})\n",
    "\n",
    "numeric_vars =  [v for v in inc_all.columns if \"inc\" in v]\n",
    "inc_all = convert_to_int(inc_all, numeric_vars)\n",
    "inc_all['total'] = inc_all['total'].astype(int)\n",
    "# Get propotion of each imcome bracket by dividing by total\n",
    "inc_all = create_proportions(inc_all, numeric_vars, \"total\")\n",
    "# Match Crime data and Get rid of MSA\n",
    "inc_all = match_crime(inc_all)\n",
    "del inc_all['MSA']\n",
    "inc_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gini</th>\n",
       "      <th>city_key</th>\n",
       "      <th>state_key</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.443</td>\n",
       "      <td>Abilene</td>\n",
       "      <td>TX</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.533</td>\n",
       "      <td>Aguadilla</td>\n",
       "      <td>PR</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.445</td>\n",
       "      <td>Akron</td>\n",
       "      <td>OH</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.481</td>\n",
       "      <td>Albany</td>\n",
       "      <td>GA</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.405</td>\n",
       "      <td>Albany</td>\n",
       "      <td>NY</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    gini   city_key state_key  year\n",
       "0  0.443    Abilene        TX  2006\n",
       "1  0.533  Aguadilla        PR  2006\n",
       "2  0.445      Akron        OH  2006\n",
       "3  0.481     Albany        GA  2006\n",
       "4  0.405     Albany        NY  2006"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###############\n",
    "# GINI INDEX\n",
    "###############\n",
    "gini_all = pd.DataFrame()\n",
    "for year in range(2006, 2017):\n",
    "    f = get_file_name(year, 'B19083')\n",
    "    gini = pd.read_csv(\"data/gini/%s.csv\" %f, encoding='Latin-1')\n",
    "    # Don't need micro areas\n",
    "    gini = slim_df(gini, [\"HD01_VD01\"])\n",
    "    gini['year'] = year\n",
    "    gini_all = append_df(gini, gini_all) \n",
    "\n",
    "# Clean Final Dataframes\n",
    "gini_all = gini_all.rename(index=str,\n",
    "                           columns={\"HD01_VD01\":\"gini\"})\n",
    "gini_all['gini'] = gini_all['gini'].astype(float)\n",
    "gini_all = match_crime(gini_all)\n",
    "del gini_all['MSA']\n",
    "gini_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>under_18_pov</th>\n",
       "      <th>18_64_pov</th>\n",
       "      <th>male_pov</th>\n",
       "      <th>female_pov</th>\n",
       "      <th>city_key</th>\n",
       "      <th>state_key</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20.4</td>\n",
       "      <td>14.9</td>\n",
       "      <td>15.5</td>\n",
       "      <td>16.1</td>\n",
       "      <td>Abilene</td>\n",
       "      <td>TX</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67.4</td>\n",
       "      <td>53.4</td>\n",
       "      <td>56.3</td>\n",
       "      <td>57.6</td>\n",
       "      <td>Aguadilla</td>\n",
       "      <td>PR</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15.7</td>\n",
       "      <td>12.5</td>\n",
       "      <td>10.7</td>\n",
       "      <td>14.6</td>\n",
       "      <td>Akron</td>\n",
       "      <td>OH</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31.0</td>\n",
       "      <td>20.7</td>\n",
       "      <td>20.7</td>\n",
       "      <td>24.7</td>\n",
       "      <td>Albany</td>\n",
       "      <td>GA</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.2</td>\n",
       "      <td>8.6</td>\n",
       "      <td>8.7</td>\n",
       "      <td>10.9</td>\n",
       "      <td>Albany</td>\n",
       "      <td>NY</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  under_18_pov 18_64_pov male_pov female_pov   city_key state_key  year\n",
       "0         20.4      14.9     15.5       16.1    Abilene        TX  2006\n",
       "1         67.4      53.4     56.3       57.6  Aguadilla        PR  2006\n",
       "2         15.7      12.5     10.7       14.6      Akron        OH  2006\n",
       "3         31.0      20.7     20.7       24.7     Albany        GA  2006\n",
       "4         13.2       8.6      8.7       10.9     Albany        NY  2006"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#################\n",
    "# Poverty Data\n",
    "#################\n",
    "pov_all = pd.DataFrame()\n",
    "for year in range(2006, 2017):\n",
    "    f = get_file_name(year, 'S1701')\n",
    "    pov = pd.read_csv(\"data/poverty/%s.csv\" %f, encoding='Latin-1')\n",
    "    pov = slim_df(pov, ['HC03_EST_VC03', 'HC03_EST_VC05',\n",
    "                       'HC03_EST_VC08', 'HC03_EST_VC09'])\n",
    "    pov['year'] = year\n",
    "    pov_all = append_df(pov, pov_all)\n",
    "# Clean Final DataFrame\n",
    "pov_all = pov_all.rename(index=str,\n",
    "                        columns={'HC03_EST_VC03': 'under_18_pov',\n",
    "                                'HC03_EST_VC05':'18_64_pov',\n",
    "                                'HC03_EST_VC08':'male_pov',\n",
    "                                'HC03_EST_VC09':'female_pov'})\n",
    "pov_all = match_crime(pov_all)\n",
    "del pov_all['MSA']\n",
    "pov_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city_key</th>\n",
       "      <th>state_key</th>\n",
       "      <th>married_house</th>\n",
       "      <th>female_house</th>\n",
       "      <th>male_house</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abilene</td>\n",
       "      <td>TX</td>\n",
       "      <td>0.661882</td>\n",
       "      <td>0.253355</td>\n",
       "      <td>0.007038</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aguadilla</td>\n",
       "      <td>PR</td>\n",
       "      <td>0.625417</td>\n",
       "      <td>0.324838</td>\n",
       "      <td>0.004308</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Akron</td>\n",
       "      <td>OH</td>\n",
       "      <td>0.686886</td>\n",
       "      <td>0.246946</td>\n",
       "      <td>0.008047</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Albany</td>\n",
       "      <td>GA</td>\n",
       "      <td>0.505709</td>\n",
       "      <td>0.429540</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Albany</td>\n",
       "      <td>NY</td>\n",
       "      <td>0.668823</td>\n",
       "      <td>0.251285</td>\n",
       "      <td>0.013663</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    city_key state_key  married_house  female_house  male_house  year\n",
       "0    Abilene        TX       0.661882      0.253355    0.007038  2006\n",
       "1  Aguadilla        PR       0.625417      0.324838    0.004308  2006\n",
       "2      Akron        OH       0.686886      0.246946    0.008047  2006\n",
       "3     Albany        GA       0.505709      0.429540    0.000000  2006\n",
       "4     Albany        NY       0.668823      0.251285    0.013663  2006"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#################################\n",
    "# Head of Household Information\n",
    "#################################\n",
    "house_all = pd.DataFrame()\n",
    "for year in range(2006, 2017):\n",
    "    f = get_file_name(year, 'B09005')\n",
    "    house = pd.read_csv(\"data/house_head/%s.csv\" %f, encoding='Latin-1')\n",
    "    house = slim_df(house, [v for v in house.columns if \"HD01\" in v])\n",
    "    house = house.loc[:, [\"MSA\", \"city_key\", \"state_key\",\n",
    "                         \"HD01_VD01\", \"HD01_VD03\", \"HD01_VD05\",\n",
    "                         \"HD01_VD06\"]]\n",
    "    house['year'] = year\n",
    "    house_all = append_df(house, house_all) \n",
    "\n",
    "# Clean Entire DataFrame\n",
    "house_all = house_all.rename(index=str,\n",
    "                             columns={'HD01_VD01': 'total',\n",
    "                                     'HD01_VD03': 'married_house',\n",
    "                                     'HD01_VD05': 'female_house',\n",
    "                                     'HD01_VD06': 'male_house'})\n",
    "\n",
    "house_all = convert_to_int(house_all,\n",
    "                       ['total', 'married_house', 'female_house', 'male_house'])\n",
    "house_all = create_proportions(house_all, ['married_house', 'female_house', 'male_house'], 'total')\n",
    "house_all = match_crime(house_all)\n",
    "del house_all['MSA']\n",
    "house_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no_hs_18_24</th>\n",
       "      <th>hs_18_24</th>\n",
       "      <th>no_9th_25_ovr</th>\n",
       "      <th>no_hs_25_ovr</th>\n",
       "      <th>hs_25_ovr</th>\n",
       "      <th>city_key</th>\n",
       "      <th>state_key</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.8</td>\n",
       "      <td>30.2</td>\n",
       "      <td>7.5</td>\n",
       "      <td>14.5</td>\n",
       "      <td>28.6</td>\n",
       "      <td>Abilene</td>\n",
       "      <td>TX</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23.4</td>\n",
       "      <td>30.6</td>\n",
       "      <td>32.7</td>\n",
       "      <td>11.7</td>\n",
       "      <td>25.0</td>\n",
       "      <td>Aguadilla</td>\n",
       "      <td>PR</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11.6</td>\n",
       "      <td>34.1</td>\n",
       "      <td>2.4</td>\n",
       "      <td>8.9</td>\n",
       "      <td>34.4</td>\n",
       "      <td>Akron</td>\n",
       "      <td>OH</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29.1</td>\n",
       "      <td>22.1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>12.2</td>\n",
       "      <td>31.5</td>\n",
       "      <td>Albany</td>\n",
       "      <td>GA</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.9</td>\n",
       "      <td>29.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>6.9</td>\n",
       "      <td>30.5</td>\n",
       "      <td>Albany</td>\n",
       "      <td>NY</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  no_hs_18_24 hs_18_24 no_9th_25_ovr no_hs_25_ovr hs_25_ovr   city_key  \\\n",
       "0        10.8     30.2           7.5         14.5      28.6    Abilene   \n",
       "1        23.4     30.6          32.7         11.7      25.0  Aguadilla   \n",
       "2        11.6     34.1           2.4          8.9      34.4      Akron   \n",
       "3        29.1     22.1           7.0         12.2      31.5     Albany   \n",
       "4        11.9     29.7           3.2          6.9      30.5     Albany   \n",
       "\n",
       "  state_key  year  \n",
       "0        TX  2006  \n",
       "1        PR  2006  \n",
       "2        OH  2006  \n",
       "3        GA  2006  \n",
       "4        NY  2006  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#################\n",
    "# Education Data\n",
    "#################\n",
    "edu_all = pd.DataFrame()\n",
    "for year in range(2006,2017):\n",
    "    f = get_file_name(year, 'S1501')\n",
    "    edu = pd.read_csv(\"data/education/%s.csv\" %f, encoding='Latin-1')\n",
    "    if 2015 <= year <= 2016:\n",
    "        edu = slim_df(edu, ['HC02_EST_VC03', 'HC02_EST_VC04', 'HC02_EST_VC09','HC02_EST_VC10', 'HC02_EST_VC11'])\n",
    "    elif 2010 <= year <= 2014:\n",
    "        edu = slim_df(edu,['HC01_EST_VC02', 'HC01_EST_VC03', 'HC01_EST_VC08','HC01_EST_VC09', 'HC01_EST_VC10'])\n",
    "    else:\n",
    "        edu = slim_df(edu, ['HC01_EST_VC02', 'HC01_EST_VC03', 'HC01_EST_VC07','HC01_EST_VC08', 'HC01_EST_VC09'])\n",
    "    \n",
    "    edu['year'] = year\n",
    "    edu.columns=['no_hs_18_24','hs_18_24','no_9th_25_ovr','no_hs_25_ovr','hs_25_ovr','MSA','city_key','state_key','year']\n",
    "    edu_all = append_df(edu, edu_all)\n",
    "\n",
    "#Trim Final Dataframe\n",
    "edu_all = match_crime(edu_all)\n",
    "del edu_all['MSA']\n",
    "edu_all.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city_key</th>\n",
       "      <th>state_key</th>\n",
       "      <th>white</th>\n",
       "      <th>black</th>\n",
       "      <th>asian</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abilene</td>\n",
       "      <td>TX</td>\n",
       "      <td>0.741838</td>\n",
       "      <td>0.068295</td>\n",
       "      <td>0.014292</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aguadilla</td>\n",
       "      <td>PR</td>\n",
       "      <td>0.896527</td>\n",
       "      <td>0.019961</td>\n",
       "      <td>0.000758</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Akron</td>\n",
       "      <td>OH</td>\n",
       "      <td>0.844866</td>\n",
       "      <td>0.116880</td>\n",
       "      <td>0.017715</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Albany</td>\n",
       "      <td>GA</td>\n",
       "      <td>0.485957</td>\n",
       "      <td>0.494136</td>\n",
       "      <td>0.006355</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Albany</td>\n",
       "      <td>NY</td>\n",
       "      <td>0.867237</td>\n",
       "      <td>0.070216</td>\n",
       "      <td>0.030761</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    city_key state_key     white     black     asian  year\n",
       "0    Abilene        TX  0.741838  0.068295  0.014292  2006\n",
       "1  Aguadilla        PR  0.896527  0.019961  0.000758  2006\n",
       "2      Akron        OH  0.844866  0.116880  0.017715  2006\n",
       "3     Albany        GA  0.485957  0.494136  0.006355  2006\n",
       "4     Albany        NY  0.867237  0.070216  0.030761  2006"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############\n",
    "# Race Data\n",
    "############\n",
    "race_all = pd.DataFrame()\n",
    "for year in range(2006, 2017):\n",
    "    f = get_file_name(year, 'B02001')\n",
    "    race = pd.read_csv(\"data/race/%s.csv\" %f, encoding='Latin-1')\n",
    "    race = slim_df(race, [v for v in race.columns if \"HD01\" in v])\n",
    "    race = race.loc[:, ['MSA', 'city_key', 'state_key',\n",
    "                       'HD01_VD01','HD01_VD02',\n",
    "                       'HD01_VD03', 'HD01_VD05']]\n",
    "    \n",
    "    race['year'] = year\n",
    "    race_all = append_df(race, race_all)\n",
    "\n",
    "# Proccess Final Data Frame\n",
    "race_all =  race_all.rename(index=str,\n",
    "                            columns={'HD01_VD01':'total',\n",
    "                                    'HD01_VD02': 'white',\n",
    "                                    'HD01_VD03': 'black',\n",
    "                                    'HD01_VD05': 'asian'})\n",
    "\n",
    "race_all = convert_to_int(race_all, ['total', 'white','black','asian'] )\n",
    "race_all = create_proportions(race_all, ['white', 'black', 'asian'], 'total')\n",
    "# Match Crime Data\n",
    "race_all = match_crime(race_all)\n",
    "del race_all['MSA']\n",
    "race_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nHousehold had ones where it looks like there may be mismatches but code below checked it\\n\\nCode to check merges\\nnames = census_df.loc[census_df._merge != \"both\", [\\'city_key\\', \\'state_key\\', \\'_merge\\']]\\nnames = names.sort_values[\\'city_key\\', \\'state_key\\']\\nnames = names.drop_duplicates()\\nprint(names.shape[0])\\nnames.head(50)\\n'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bring Everything Together\n",
    "census_df = race_all.copy()\n",
    "\n",
    "merge_df = lambda df: census_df.merge(df,\n",
    "                                     how='outer',\n",
    "                                     on=['city_key','state_key','year'],\n",
    "                                     indicator=True)\n",
    "\n",
    "str_list = ['Employment', 'Age', 'Head of House','Education', 'Gini', 'Poverty']\n",
    "df_list = [emp_all, age_all, house_all, edu_all, gini_all, pov_all]\n",
    "\n",
    "for i, df in enumerate(df_list):\n",
    "    census_df = merge_df(df)\n",
    "    #print(\"%s Merge Stats\" %str_list[i])\n",
    "    #print(census_df['_merge'].value_counts())\n",
    "    del census_df['_merge']\n",
    "    \n",
    "'''\n",
    "\n",
    "Household had ones where it looks like there may be mismatches but code below checked it\n",
    "\n",
    "Code to check merges\n",
    "names = census_df.loc[census_df._merge != \"both\", ['city_key', 'state_key', '_merge']]\n",
    "names = names.sort_values['city_key', 'state_key']\n",
    "names = names.drop_duplicates()\n",
    "print(names.shape[0])\n",
    "names.head(50)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################\n",
    "# Bring in BEA Data\n",
    "#####################\n",
    "bea_gdp = pd.read_csv(\"data/BEA_real_GDP_pc.csv\",skiprows=[0,1,2], header=1)\n",
    "del bea_gdp['Fips']\n",
    "bea_gdp= bea_gdp.iloc[1:, :].rename(index=str, columns={\"Area\": 'MSA'})\n",
    "bea_gdp = pd.melt(bea_gdp, id_vars=[\"MSA\"], var_name='year', value_name='real_pc_gdp')\n",
    "bea_gdp = bea_gdp.loc[bea_gdp.MSA.notnull(), :]\n",
    "bea_gdp['year'] = bea_gdp['year'].astype(int)\n",
    "bea_gdp = bea_gdp.loc[bea_gdp.year >= 2006, :]\n",
    "\n",
    "# Get rid of MSA in paranthesis\n",
    "bea_gdp['MSA'] = bea_gdp['MSA'].str.replace(r\"\\(.*\\)\",\"\")\n",
    "bea_gdp = split_MSA(bea_gdp)\n",
    "# Need to manually fix this one so it will merge\n",
    "bea_gdp.loc[bea_gdp.city_key.str.contains(\"Louisville\"), 'city_key'] = 'Louisville'\n",
    "\n",
    "del bea_gdp['MSA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "census_df = merge_df(bea_gdp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49\n"
     ]
    }
   ],
   "source": [
    "# Check to make sure that there were no typos\n",
    "names = census_df.loc[census_df._merge != \"both\", ['city_key', 'state_key', '_merge']]\n",
    "names = names.drop_duplicates()\n",
    "print(names.shape[0])\n",
    "del census_df[\"_merge\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city_key</th>\n",
       "      <th>state_key</th>\n",
       "      <th>white</th>\n",
       "      <th>black</th>\n",
       "      <th>asian</th>\n",
       "      <th>year</th>\n",
       "      <th>unemp_16_ovr</th>\n",
       "      <th>unemp_16_19</th>\n",
       "      <th>unemp_female</th>\n",
       "      <th>median_age</th>\n",
       "      <th>...</th>\n",
       "      <th>hs_18_24</th>\n",
       "      <th>no_9th_25_ovr</th>\n",
       "      <th>no_hs_25_ovr</th>\n",
       "      <th>hs_25_ovr</th>\n",
       "      <th>gini</th>\n",
       "      <th>under_18_pov</th>\n",
       "      <th>18_64_pov</th>\n",
       "      <th>male_pov</th>\n",
       "      <th>female_pov</th>\n",
       "      <th>real_pc_gdp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abilene</td>\n",
       "      <td>TX</td>\n",
       "      <td>0.741838</td>\n",
       "      <td>0.068295</td>\n",
       "      <td>0.014292</td>\n",
       "      <td>2006</td>\n",
       "      <td>6.6</td>\n",
       "      <td>23.1</td>\n",
       "      <td>5.2</td>\n",
       "      <td>34.4</td>\n",
       "      <td>...</td>\n",
       "      <td>30.2</td>\n",
       "      <td>7.5</td>\n",
       "      <td>14.5</td>\n",
       "      <td>28.6</td>\n",
       "      <td>0.443</td>\n",
       "      <td>20.4</td>\n",
       "      <td>14.9</td>\n",
       "      <td>15.5</td>\n",
       "      <td>16.1</td>\n",
       "      <td>33978.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aguadilla</td>\n",
       "      <td>PR</td>\n",
       "      <td>0.896527</td>\n",
       "      <td>0.019961</td>\n",
       "      <td>0.000758</td>\n",
       "      <td>2006</td>\n",
       "      <td>20.6</td>\n",
       "      <td>56.8</td>\n",
       "      <td>19.1</td>\n",
       "      <td>35.3</td>\n",
       "      <td>...</td>\n",
       "      <td>30.6</td>\n",
       "      <td>32.7</td>\n",
       "      <td>11.7</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.533</td>\n",
       "      <td>67.4</td>\n",
       "      <td>53.4</td>\n",
       "      <td>56.3</td>\n",
       "      <td>57.6</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Akron</td>\n",
       "      <td>OH</td>\n",
       "      <td>0.844866</td>\n",
       "      <td>0.116880</td>\n",
       "      <td>0.017715</td>\n",
       "      <td>2006</td>\n",
       "      <td>6.3</td>\n",
       "      <td>23.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>37.9</td>\n",
       "      <td>...</td>\n",
       "      <td>34.1</td>\n",
       "      <td>2.4</td>\n",
       "      <td>8.9</td>\n",
       "      <td>34.4</td>\n",
       "      <td>0.445</td>\n",
       "      <td>15.7</td>\n",
       "      <td>12.5</td>\n",
       "      <td>10.7</td>\n",
       "      <td>14.6</td>\n",
       "      <td>42081.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Albany</td>\n",
       "      <td>GA</td>\n",
       "      <td>0.485957</td>\n",
       "      <td>0.494136</td>\n",
       "      <td>0.006355</td>\n",
       "      <td>2006</td>\n",
       "      <td>10.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>10.1</td>\n",
       "      <td>34.3</td>\n",
       "      <td>...</td>\n",
       "      <td>22.1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>12.2</td>\n",
       "      <td>31.5</td>\n",
       "      <td>0.481</td>\n",
       "      <td>31.0</td>\n",
       "      <td>20.7</td>\n",
       "      <td>20.7</td>\n",
       "      <td>24.7</td>\n",
       "      <td>32657.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Albany</td>\n",
       "      <td>NY</td>\n",
       "      <td>0.867237</td>\n",
       "      <td>0.070216</td>\n",
       "      <td>0.030761</td>\n",
       "      <td>2006</td>\n",
       "      <td>5.4</td>\n",
       "      <td>16.8</td>\n",
       "      <td>4.4</td>\n",
       "      <td>38.2</td>\n",
       "      <td>...</td>\n",
       "      <td>29.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>6.9</td>\n",
       "      <td>30.5</td>\n",
       "      <td>0.405</td>\n",
       "      <td>13.2</td>\n",
       "      <td>8.6</td>\n",
       "      <td>8.7</td>\n",
       "      <td>10.9</td>\n",
       "      <td>49549.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    city_key state_key     white     black     asian  year unemp_16_ovr  \\\n",
       "0    Abilene        TX  0.741838  0.068295  0.014292  2006          6.6   \n",
       "1  Aguadilla        PR  0.896527  0.019961  0.000758  2006         20.6   \n",
       "2      Akron        OH  0.844866  0.116880  0.017715  2006          6.3   \n",
       "3     Albany        GA  0.485957  0.494136  0.006355  2006         10.0   \n",
       "4     Albany        NY  0.867237  0.070216  0.030761  2006          5.4   \n",
       "\n",
       "  unemp_16_19 unemp_female median_age     ...     hs_18_24  no_9th_25_ovr  \\\n",
       "0        23.1          5.2       34.4     ...         30.2            7.5   \n",
       "1        56.8         19.1       35.3     ...         30.6           32.7   \n",
       "2        23.0          4.8       37.9     ...         34.1            2.4   \n",
       "3        31.0         10.1       34.3     ...         22.1            7.0   \n",
       "4        16.8          4.4       38.2     ...         29.7            3.2   \n",
       "\n",
       "   no_hs_25_ovr hs_25_ovr   gini under_18_pov  18_64_pov  male_pov  \\\n",
       "0          14.5      28.6  0.443         20.4       14.9      15.5   \n",
       "1          11.7      25.0  0.533         67.4       53.4      56.3   \n",
       "2           8.9      34.4  0.445         15.7       12.5      10.7   \n",
       "3          12.2      31.5  0.481         31.0       20.7      20.7   \n",
       "4           6.9      30.5  0.405         13.2        8.6       8.7   \n",
       "\n",
       "   female_pov real_pc_gdp  \n",
       "0        16.1     33978.0  \n",
       "1        57.6         NaN  \n",
       "2        14.6     42081.0  \n",
       "3        24.7     32657.0  \n",
       "4        10.9     49549.0  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "census_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Crime Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pulling: 2006\n",
      "Pulling: 2007\n",
      "Pulling: 2008\n",
      "Pulling: 2009\n",
      "Pulling: 2010\n",
      "Pulling: 2011\n"
     ]
    }
   ],
   "source": [
    "# THIS CODE ONLY NEEDS TO BE RUN ONCE TO BRING IN ALL OF THE EXCEL FILES\n",
    "version='Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.75 Safari/537.36'\n",
    "test=urllib.request.URLopener()\n",
    "test.addheader('User-Agent',version)\n",
    "for year in range(2006, 2017):\n",
    "    print(\"Pulling: %i\" %year)\n",
    "    test.retrieve(url=fbi_url_generator(year),filename='crime_%i.xls' %year)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_allyears = pd.DataFrame()\n",
    "for year in range(2006, 2017):\n",
    "    df = pd.read_excel(\"crime_%i.xls\" %year,skiprows=[0,1],header=1)\n",
    "\n",
    "    #######\n",
    "    # NOTE - misc column has msa population, city population and estimate percentage\n",
    "    ######\n",
    "    df=df.iloc[:,0:12] \n",
    "    df.columns=['MSA', 'counties','misc', 'violent_crime','mur_mans', 'rape', 'robbery',\n",
    "                'assault', 'property', 'burglary', 'larceny','mv_theft']\n",
    "    \n",
    "    df['counties'].replace(' ',np.nan, inplace=True)\n",
    "\n",
    "    # Drop footnotes\n",
    "    footnotes = df['MSA'].str[0].str.isdigit().fillna(False)\n",
    "    df = df.loc[~footnotes, :]\n",
    "    \n",
    "    #Drop blank rows\n",
    "    df = df.dropna(how='all')\n",
    "\n",
    "    # Get rid of numbers in MSA\n",
    "    df['MSA'] = df['MSA'].str.replace('\\d+', '')\n",
    "    # Set empty columns to NaN for MSA\n",
    "    df['MSA'] = df['MSA'].replace(' ', np.nan, regex=False)\n",
    "    \n",
    "    # Sometimes city  names get put in MSA column\n",
    "    # Messes up carry forward\n",
    "    df.loc[df['MSA'].str.contains(\"City of\").fillna(False), \"MSA\"] = np.nan\n",
    "\n",
    "    # Carry MSA name forward to fill in for all cells\n",
    "    df.loc[:,'MSA'] = df.loc[:, 'MSA'].fillna(method='ffill')\n",
    "\n",
    "    ##############\n",
    "    # POPULATION - grab population and fill in for all MSA\n",
    "    ##############\n",
    "    pop_row = df.counties.isnull()\n",
    "    pop = df.loc[pop_row, [\"MSA\", 'misc']]\n",
    "    pop = pop.rename(index=str, columns={'misc': 'msa_pop'})\n",
    "    \n",
    "    # Merge population back in\n",
    "    df = df.loc[~pop_row, :]\n",
    "    df = df.merge(pop, how='outer', on='MSA')\n",
    "\n",
    "    ################\n",
    "    # Descriptions - don't need county descriptions \n",
    "    ################\n",
    "    df = df.loc[df.counties.str.contains(\"Includes\") == False, :]\n",
    "\n",
    "\n",
    "    ###########################################\n",
    "    # GOING LONG TO WIDE FOR CRIME VARIABLES\n",
    "    ###########################################\n",
    "    crime_vars = ['violent_crime','mur_mans', 'rape', 'robbery',\n",
    "                  'assault', 'property', 'burglary', 'larceny','mv_theft']\n",
    "\n",
    "    #########\n",
    "    # CITIES\n",
    "    #########\n",
    "    city_vars = ['MSA', 'counties', 'misc'] + crime_vars\n",
    "    # Split data Frame\n",
    "    cities = df.counties.str.contains(\"City\")\n",
    "    city_df = df.loc[cities, city_vars]\n",
    "    city_df = city_df.rename(index=str, columns={'misc': 'city_pop'})\n",
    "    \n",
    "    # Grab largest city for each MSA and merge back on\n",
    "    city_df = city_df.sort_values(['MSA','city_pop'], ascending=False)\n",
    "    large_city = city_df.groupby('MSA').first().reset_index()\n",
    "\n",
    "    # Rename crime variables to denote city only crime \n",
    "    large_city.columns = ['MSA', 'counties', 'city_pop'] + ['city_' + i for i in crime_vars]\n",
    "    large_city = large_city.rename(index=str, columns={'counties':'largest_city'})\n",
    "    # Get rid of \"City of\"\n",
    "    large_city.loc[:,'largest_city'] = large_city.loc[:, 'largest_city'].str.replace('City of','')\n",
    "    \n",
    "    # Merge back to main dataframe\n",
    "    df = df.loc[~cities, ]\n",
    "    df = df.merge(large_city, how='outer', on='MSA')\n",
    "\n",
    "    ###############\n",
    "    # CRIME RATE\n",
    "    ###############\n",
    "    rates = df.counties.str.contains(\"Rate per\")\n",
    "    rate_vars = ['MSA'] + crime_vars\n",
    "    rates_df = df.loc[rates, rate_vars]\n",
    "    rates_df.columns = ['MSA'] + ['rate_' + i for i in crime_vars]\n",
    "\n",
    "    df = df.loc[~rates, :]\n",
    "    df = df.merge(rates_df, how='outer', on='MSA')\n",
    "\n",
    "    ########################\n",
    "    # MSA-WIDE CRIME STATS\n",
    "    ########################\n",
    "\n",
    "    # If the entire MSA reported then there is just one row of numbers\n",
    "    # If the entire MSA did not report, then there are two rows\n",
    "            # first row is areas that reported\n",
    "            # second report is an estimated total\n",
    "    # We are going to grab the estimates total so our data\n",
    "    # reflects all areas for all MSA\n",
    "\n",
    "    # Create Flag for those that do not have complete coverage\n",
    "    # and are thus estimates\n",
    "    mins = df.groupby('MSA').misc.min().reset_index()\n",
    "    mins.columns = ['MSA', 'min_coverage']\n",
    "    df = df.merge(mins, how='outer', on='MSA')\n",
    "    df['estimate'] = 0\n",
    "    df.loc[df.min_coverage < 1, 'estimate'] = 1\n",
    "    del df['min_coverage']\n",
    "\n",
    "    # Now only keeping rows with coverage = 1\n",
    "    # will either be all area or the estimate for all area\n",
    "    df = df.loc[df.misc == 1, :]\n",
    "\n",
    "    # Now no longer need coverage or whether its estimate or not\n",
    "    del df['misc']\n",
    "    del df['counties']\n",
    "    \n",
    "    df['year'] = year\n",
    "    \n",
    "    # Append to existing Frame\n",
    "    df_allyears = append_df(df, df_allyears)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_allyears = df_allyears.sort_values([\"MSA\", 'year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#Generate the city\n",
    "df_allyears['city_key'] = df_allyears['MSA'].str.replace(' M.S.A.','').str.split(\",\").str[0]\n",
    "df_allyears['city_key'] = df_allyears['city_key'].str.split(\"-\").str[0].str.strip()\n",
    "df_allyears['state_key']=df_allyears['MSA'].str.replace(' M.S.A.','').str.split(\",\").str[1].str.strip().str.replace(' M.S.A','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##Cleanse Crime Data\n",
    "df_allyears=df_allyears[~df_allyears['MSA'].str.contains(' M.D.')]\n",
    "df_allyears.loc[df_allyears['state_key']=='Puerto Rico','state_key']='PR'\n",
    "df_allyears.loc[df_allyears['MSA'].str.contains('Texarkana'),'state_key']='AR-TX'\n",
    "df_allyears.loc[df_allyears['city_key']=='Worcester','state_key']='MA-CT'\n",
    "df_allyears.loc[df_allyears['city_key']=='Steubenville','city_key']='Weirton'\n",
    "df_allyears.loc[df_allyears['city_key']=='Steubenville','state_key']='WV-OH'\n",
    "df_allyears.loc[df_allyears['city_key']=='Honolulu','city_key']='Urban Honolulu'\n",
    "df_allyears.loc[df_allyears['MSA'].str.contains('Scranton'),'city_key']='Scranton'\n",
    "df_allyears.loc[df_allyears['MSA'].str.contains('Sarasota'),'city_key']='North Port'\n",
    "df_allyears.loc[df_allyears['MSA'].str.contains('Santa Maria'),'city_key']='Santa Maria'\n",
    "df_allyears.loc[df_allyears['MSA'].str.contains('Salisbury'),'state_key']='MD-DE'\n",
    "df_allyears.loc[df_allyears['MSA'].str.contains('Sacramento'),'city_key']='Sacramento'\n",
    "df_allyears.loc[df_allyears['MSA'].str.contains('Myrtle Beach'),'state_key']='SC-NC'\n",
    "df_allyears.loc[df_allyears['MSA'].str.contains('Louisville'),'city_key']='Louisville'\n",
    "df_allyears.loc[df_allyears['MSA'].str.contains('Homosassa'),'city_key']='Homosassa Springs'\n",
    "df_allyears.loc[df_allyears['MSA'].str.contains('Crestview'),'city_key']='Crestview'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge Crime & Census"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Merge Crime and census data\n",
    "final_df = df_allyears.merge(census_df, how='left', on=['city_key','state_key','year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to convert to float otherwise set to NaN\n",
    "def f(x):\n",
    "    try:\n",
    "        return np.float(x)\n",
    "    except:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Look at final Cleaning of data-types\n",
    "float_cols = final_df.columns.difference([\"MSA\", \"city_key\", \"state_key\",\"year\", \"largest_city\"])\n",
    "for v in float_cols:\n",
    "    try:\n",
    "        final_df[v] = final_df[v].astype(float)\n",
    "    except:\n",
    "        continue\n",
    "# Assault Rate Needs to be fixed\n",
    "# One Value is missing\n",
    "final_df.loc[final_df.rate_assault == \" \", 'rate_assault'] = np.nan\n",
    "final_df[\"rate_assault\"] = final_df[\"rate_assault\"].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create a join key\n",
    "final_df['join_key'] = final_df['city_key'].str.cat(final_df['state_key'],sep='-')\n",
    "#Add columns for OHE\n",
    "final_df['year_ohe'] = final_df['year']\n",
    "final_df['state_ohe'] = final_df['state_key']\n",
    "final_df['join_ohe'] = final_df['join_key']\n",
    "#One hot encode join key, state key and year\n",
    "final_df = pd.get_dummies(final_df,prefix='year',columns=['year_ohe']) #Not dropping one column since year has missing values\n",
    "final_df = pd.get_dummies(final_df,prefix=['MSA','state'],columns=['join_ohe','state_ohe'],drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_df.to_json('output/final.json')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
